import pandas as pd
from sklearn.model_selection import train_test_split       #automatically shuffle 
import torch
from torch.utils.data import Dataset, DataLoader
import torch.nn as nn
import torch.optim as optim
import matplotlib.pyplot as plt


# set manual seed for reproduciblitly
torch.manual_seed(42)


df = pd.read_csv('fmnist_small.csv')


df.head()


# create a 4x4 grid of images
fig, axes  = plt.subplots(4, 4, figsize=(10, 10))
fig.suptitle("First 16 Images", fontsize = 40)

#plot the first 16 images from the dataset
for i, ax in enumerate(axes.flat):
    img = df.iloc[i, 1:].values.reshape(28, 28)  #reshape to 28x28
    ax.imshow(img)    #display the grayscale
    ax.axis('off')
    ax.set_title(f"Labels: {df.iloc[i, 0]}")

plt.tight_layout(rect = [0, 0, 1, 0.96])
plt.show()





x = df.iloc[: , 1:].values
y = df.iloc[: , 0].values


x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)


x_train = x_train/255.0
x_test = x_test/255.0



class CustomDataset(Dataset):
    def __init__(self, features, labels):
        self.features = torch.tensor(features, dtype = torch.float32)
        self.labels = torch.tensor(labels, dtype = torch.long)
    def __len__(self):
        return len(self.features)

    def __getitem__(self, index):
        return self.features[index], self.labels[index]


# create train_dataset object
train_dataset = CustomDataset(x_train, y_train)


# create test dataset
test_dataset = CustomDataset(x_test, y_test)


train_loader = DataLoader(train_dataset, batch_size = 32, shuffle = True)
test_loader = DataLoader(test_dataset, batch_size = 32, shuffle = False)


class MyNN(nn.Module):
    def __init__(self, num_features):
        super().__init__()
        self.model = nn.Sequential(
            nn.Linear(num_features, 128),
            nn.ReLU(),
            nn.Linear(128,64),
            nn.ReLU(),
            nn.Linear(64, 10)
        )

    def forward(self, x):
        return self.model(x)
            
        


learning_rate = 0.1
epochs = 100


# instantiate the model
model = MyNN(x_train.shape[1])

# loss function
criterion = nn.CrossEntropyLoss()

# Optimizer
optimizer = optim.SGD(model.parameters(), lr = learning_rate)


len(train_loader)


# training loop
for epoch in range(epochs):
    
    total_epoch_loss = 0
    for batch_features, batch_labels in train_loader:

        # forward pass
        outputs = model(batch_features)


        # calculate loss
        loss = criterion(outputs, batch_labels)


        # backpropagation
        optimizer.zero_grad()
        loss.backward()


        # update gradients
        optimizer.step()
        total_epoch_loss+= loss.item()
    avg_loss = total_epoch_loss/len(train_loader)
    print(f'Epoch: {epoch+1} , Loss: {avg_loss}')
        


model.eval()


len(test_loader)


batch_labels


batch_features.shape


a = torch.tensor([1,2, 3, 4, 5, 600, 7, 8, 9])





total = 0
correct = 0

with torch.no_grad():
    for batch_features, batch_labels in test_loader:
        outputs = model(batch_features)
        _, predicted = torch.max(outputs, 1)

        total = total + batch_labels.shape[0]

        correct = correct + (predicted==batch_labels).sum().item()

print(correct/total)





import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import torch
from torch.utils.data import Dataset, DataLoader
from sklearn.model_selection import train_test_split


df = pd.read_csv('fmnist_small.csv')


df.head()


fig, axes = plt.subplots(4, 4, figsize=(20, 20))
fig.suptitle("first 25 images", fontsize = 40)

for i, ax in enumerate(axes.flat):
    img = df.iloc[i, 1:].values.reshape(28, 28)
    ax.imshow(img)
    ax.set_title(f"Label : {df.iloc[i,0]}")
    plt.axis('off')

plt.tight_layout(rect=[0, 0, 1, 0.96])
plt.show()
    


x = df.iloc[: , 1:].values
y = df.iloc[: , 0].values


x_train, x_test, y_train, y_test = train_test_split(x, y, random_state = 42, test_size=0.2)


x_train = x_train / 255.0
x_test = x_test / 255.0


class CustomDataset(Dataset):
    def __init__(self, features, labels):
        self.features = torch.tensor(features, dtype = torch.float32)
        self.labels = torch.tensor(labels, dtype = torch.long)
    def __len__(self):
        return len(self.features)
    def __getitem__(self, idx):
        return self.features[idx], self.labels[idx]


train_dataset = CustomDataset(x_train, y_train)
test_dataset = CustomDataset(x_test, y_test)


train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)


len(train_loader)


class MyNN(nn.Module):
    def __init__(self, num_features):
        super().__init__()
        self.model = nn.Sequential(
            nn.Linear(num_features, 128),
            nn.ReLU(),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, 10)
    )
    def forward(self, x):
        return self.model(x)

        
            


learning_rate = 0.1
epochs = 100


model = MyNN(x_train.shape[1])

criterion = nn.CrossEntropyLoss()

optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate )


for epoch in range(epochs):
    total_loss = 0
    for batch_features, batch_labels in train_loader:
        output = model(batch_features)
        loss = criterion(output, batch_labels)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
    avg_loss = total_loss/(len(train_loader))
    print(f"For Epoch {epoch+1} loss is ==================================> {avg_loss}")
        
        


model.eval()


len(test_loader)


total = 0 
correct = 0

with torch.no_grad():
    for batch_features, batch_labels in test_loader:
        outputs = model(batch_features)
        _,predicted = torch.max(outputs, 1)
        total = total + batch_features.shape[0]
        correct = correct + (predicted==batch_labels).sum().item()


print(correct/total)


# a = torch.tensor([True, True, True, False, False])
# b = torch.tensor([True, True, False, True, False])
a = torch.tensor([1, 1, 1, 0, 0])
b = torch.tensor([1, 1, 0, 1, 0])

print((a==b).sum())



