import torch
print(torch.__version__)


if torch.cuda.is_available():
  print("GPU availavle")
  print(f"using GPU: {torch.cuda.get_device_name()}")
else:
  print("GPU not available")





torch.empty(2, 3) # memory allocate karta hai


#check type
a = torch.empty(4, 3)


type(a)


torch.zeros(2,3)


torch.ones(4, 3)


torch.rand(3, 4 )


torch.manual_seed(100)
torch.rand(3, 4)


torch.manual_seed(100)
torch.rand(3, 4)


torch.tensor([[1, 2, 3, 4, 5]])


torch.arange(0, 10)


torch.linspace(0, 10, 11)


torch.eye(4)


torch.full((3, 3), 5)





x = torch.tensor([[1, 2, 3], [4, 5, 6]])
x.size()


x


torch.empty_like(x)


torch.zeros_like(x)


torch.ones_like(x)


torch.rand_like(x, dtype=torch.float32)





x.dtype


torch.tensor([1.0, 2.0, 3.0], dtype=torch.int32)


torch.tensor([1, 2, 3], dtype = torch.float64)


x.to(torch.float32)





x = torch.rand(2, 3)


x + 2


x*5


x/7


x*100


x**4


a = torch.rand(4, 5)
b = torch.rand(4, 5)
print(a)
print(b)


a+b


d = a-b
d


a*b


c = b/a


torch.abs(d)


torch.round(d)


torch.ceil(d)


torch.floor(d)


torch.clamp(d, min=2, max = 3)





e = torch.randint(size=(2, 3), low=0, high = 10, dtype = torch.float32)
e


torch.sum(e)


torch.sum(e, dim=0)


torch.sum(e, dim=1)


torch.mean(e)


torch.prod(e)


torch.std(e)


torch.var(e)


torch.argmax(e)


torch.argmin(e)


torch.argmin(e)


f = torch.randint(size= (2, 3), low = 0 , high = 10)
g = torch.randint(size= (3, 3), low = 0 , high = 10)


print(f)
print(g)


torch.transpose(f, 0, 1)


torch.det(g)


z = torch.randint(size= (3, 3), low = 0 , high = 10)


torch.log(z)


m = torch.rand(2, 3)
n = torch.rand(2, 3)


m.relu_()


print(id(m))


torch.cuda.is_available()


device = torch.device('cuda')


torch.rand((2, 3), device = device)   ##ab yeh gpu pe ban rahah hai


a = torch.rand(2, 3)
a


a.to(device)


b = a.to(device)


a


b


b + 10


import time


cpu1 = torch.rand(10000, 10000)
cpu2 = torch.rand(10000, 10000)
start = time.time()
result = torch.matmul(cpu1, cpu2)
end = time.time()
print(f"time taken si {end-start}")


gpu1 = cpu1.to(device)
gpu2 = cpu2.to(device)
start = time.time()
result = torch.matmul(gpu1, gpu2)
end = time.time()
print(f"time taken si {end-start}")


print(f"gpu is {25.158754348754883/0.1407308578491211} times faster than cpu")


a = torch.ones(4, 4)


a


a.reshape(2, 8)


a.reshape(2, 2, 2, 2)


a.flatten()


b = torch.rand(2, 3, 4)
b



b.permute(2, 1, 0).shape


b.permute(2, 1, 0)


#unsqueeze
#image size

c = torch.rand(226, 226, 3)
c.unsqueeze(0).shape


c.unsqueeze(0)


d = torch.rand(1, 20)
d.squeeze(0).shape


import numpy as np


a = torch.tensor([1, 2, 3])


a


a.numpy()


b = np.array([2, 3, 4, 5])
b


torch.from_numpy(b)


import torch
x = torch.tensor([2, 3, 4, 5, 6])


x


x.view(-1, 1)


x


y = x.view(-1)


y


y[2] = 8


y


x



