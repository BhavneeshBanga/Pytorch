import pandas as pd
from sklearn.model_selection import train_test_split       #automatically shuffle 
import torch
from torch.utils.data import Dataset, DataLoader
import torch.nn as nn
import torch.optim as optim
import matplotlib.pyplot as plt


# set manual seed for reproduciblitly
torch.manual_seed(42)


df = pd.read_csv('fmnist_small.csv')


# create a 4x4 grid of images
fig, axes  = plt.subplots(4, 4, figsize=(10, 10))
fig.suptitle("First 16 Images", fontsize = 40)

#plot the first 16 images from the dataset
for i, ax in enumerate(axes.flat):
    img = df.iloc[i, 1:].values.reshape(28, 28)  #reshape to 28x28
    ax.imshow(img)    #display the grayscale
    ax.axis('off')
    ax.set_title(f"Labels: {df.iloc[i, 0]}")

plt.tight_layout(rect = [0, 0, 1, 0.96])
plt.show()


x = df.iloc[: , 1:].values
y = df.iloc[: , 0].values


x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)


x_train = x_train/255.0
x_test = x_test/255.0



class CustomDataset(Dataset):
    def __init__(self, features, labels):
        self.features = torch.tensor(features, dtype = torch.float32)
        self.labels = torch.tensor(labels, dtype = torch.long)
    def __len__(self):
        return len(self.features)

    def __getitem__(self, index):
        return self.features[index], self.labels[index]


# create train_dataset object
train_dataset = CustomDataset(x_train, y_train)
# create test dataset
test_dataset = CustomDataset(x_test, y_test)


train_loader = DataLoader(train_dataset, batch_size = 32, shuffle = True)
test_loader = DataLoader(test_dataset, batch_size = 32, shuffle = False)


class MyNN(nn.Module):
    def __init__(self, num_features):
        super().__init__()
        self.model = nn.Sequential(
            nn.Linear(num_features, 128),
            nn.ReLU(),
            nn.Linear(128,64),
            nn.ReLU(),
            nn.Linear(64, 10)
        )

    def forward(self, x):
        return self.model(x)
            
        


learning_rate = 0.1
epochs = 100


# instantiate the model
model = MyNN(x_train.shape[1])

# loss function
criterion = nn.CrossEntropyLoss()

# Optimizer
optimizer = optim.SGD(model.parameters(), lr = learning_rate)


# training loop
for epoch in range(epochs):
    
    total_epoch_loss = 0
    for batch_features, batch_labels in train_loader:

        # forward pass
        outputs = model(batch_features)


        # calculate loss
        loss = criterion(outputs, batch_labels)


        # backpropagation
        optimizer.zero_grad()
        loss.backward()


        # update gradients
        optimizer.step()
        total_epoch_loss+= loss.item()
    avg_loss = total_epoch_loss/len(train_loader)
    print(f'Epoch: {epoch+1} , Loss: {avg_loss}')
        


torch.save(model.state_dict(), "Model_weights.pth")



